\documentclass[10pt, a4paper]{article}

\input{includes}

\title{Rapport}
\author{GOEDEFROIT Charles}
\subject{Sur l'article : Arbitration Policies for On-Demand User-Level I/O Forwarding on HPC Platforms\cite{9460487}}
\keywords{}
\date{\today}

\input{configs}

\begin{document}

\begin{titlepage}
	\centering
  \ {} % important
	\vfill
	\vspace{1cm}
	{\scshape\Huge\MyTitle\par}
	\vspace{0.5cm}
	{\Large\MySubject\par}
	\vspace{1cm}
	\MyAuthor
	\vfill
	{\large\MyDate\par}
\end{titlepage}

\newpage

\section{L'objectif de l'article}

L'objectif de l'article est d'améliorer l'utilisation de la bande passante entre les \noeudsDeCalculs{} et les \emph{noeuds de stockage des données}, que j'appellerai \noeudsIO{} dans le reste de ce rapport. Plus précisément, l'objectif est de permettre le changement dynamique des politiques d'accès aux \noeudsIO{}. Pour cela, l'article propose :
\begin{itemize}
  \item une implémentation qui permet ce changement en fonction des patterns d'accès aux \noeudsIO{}.
  \item ainsi qu'une politique basé sur le problème du sac à dos à choix multiple (\emph{Multiple-Choice Knapsack problem}).
\end{itemize}

Il propose aussi une solution qui permet d'utiliser dynamiquement différentes politiques d'allocation de \noeudsIOforwarding{}.

\section{Le context de l'article}

Cet article se place dans le contexte ou les supercalculateurs font de plus en
plus d'accès aux données. Cette augmentation est due à plusieurs facteurs comme :
\begin{itemize}
  \item l'augmentation de la puissance de calcul.
  \item l'augmentation des quantités de données a traité.
  \item la variété des types d'applications à accès hétérogène aux données, l'intelligence artificielle, le bigData\dots
\end{itemize}
Pour répondre au besoin de puissance croissante, on augmente le nombre de \noeudsDeCalculs{} ce qui a pour effet d'augmenter le nombre de requêtes au système de fichier parallèle (\emph{PFS}). Ce système fini par ne plus pouvoir traité autant de requêtes, car tous les \noeudsIO{} se retrouvent saturés. Pour réglé ce problème les \emph{PFS} utilise la technique du \emph{I/O forwarding} qui diminue le nombre de noeuds du \emph{PFS} accessible par les \noeudsDeCalculs{}.

\subsection{La technique du \emph{I/O forwarding}}

Cette technique est très utilisée pour le calcul haut performance, notamment par des machines du top 500\footnote[1]{November 2020 TOP500: https://www.top500.org/lists/2020/06/.}. Elle permet d'augmenter les performances globales en diminuant la concentration des requêtes sur les \noeudsIO{}. Pour cela, elle évite les accès directs aux \noeudsIO{} en se plaçant entre les \noeudsDeCalculs{} et les \noeudsIO{}. Concrètement, un groupe de \noeudsIO{} reçoit les requêtes et appliquent des traitements avant de les transmettre aux bons \noeudsIO{}. Cette technique est transparente pour les utilisateurs, elle cherche à appliquer une répartition uniforme entre les noeuds et permet le contrôle des demandes d'accès aux données ce qui permet l'application de technique d'optimisation. Ces techniques peuvent être de différentes natures comme l'agrégation des requêtes (en combinant plusieurs petites requêtes) ou la planification des requêtes.

Habituellement les \noeudsIO{} qui s'occupent de la réception des requêtes sont assigné statiquement à un \noeudDeCalculs{} et celle-ci peut dépendre de la topologie du réseau, du nombre de \noeudsIO{}\dots Cette assignation ne correspond pas tout le temps au besoin de l'application qui peut ne pas utiliser toute la bande passante ou être ralentie par celle-ci. L'assignation statique amène donc à une mauvaise utilisation des ressources. Dans la suite du rapport, j'appellerai les \noeudsIO{} qui s'occupent de la réception les \noeudsIOforwarding{}.

\section{Le problème traité par l'article}

L'article cherche à corriger les problèmes de l'allocation statique en proposant une allocation dynamique.
Les problèmes de l'allocation statique sont :
\begin{itemize}
  \item Le nombre de \noeudsIO{} et prédéfinis et donc ne peut pas changer pendant l'exécution ou s'adapter à une application.
  \item Ce n'est pas flexible, car la politique d'allocation des \noeudsIO{} reste la même tout au long de l'exécution.
  \item On peut être amené à de mauvaises allocations des ressources (L'article cite les travaux de Yu et al. \cite{8322970} Bez et al. \cite{9307161}).
  \item En fonction de l'application, on peut ce retrouvé avec une bande passante peu utiliser ou qui ralentit l'application. Ce qui fait qu'on utilise pas assez ou trop de \noeudsIO{}.
  \item Ne permets pas le changement facile de la stratégie d'allocation sans avoir un mauvais impacte sur les performances.
\end{itemize}

\subsection{Évaluations des politiques d'allocations}

Dans l'article, ils ont commencé par évaluer les politiques d'allocation suivante :
\begin{itemize}
  \item \emph{ZERO and ONE Policies} chaque application à 0 ou un \noeudIO{} alloué.
  \item \emph{STATIC Policy} le nombre de \noeudsIO{} est déterminé par rapport au nombre de \noeudsDeCalculs{}.
  \item \emph{SIZE and PROCESS Policies} le nombre de \noeudsIO{} est réparti proportionnellement entre les applications par rapport à leur nombre de \noeudsDeCalculs{} ou leur nombre de processus.
  \item \emph{ORACLE Policy} chaque application se voit allouer un nombre de \noeudsIO{} qui maximise l'utilisation de la bande passante. Cette allocation est déterminée par une évaluation des performances.
\end{itemize}

Ils ont effectué ces évaluations en faisant plusieurs lancements avec différents nombres de \noeudsIO, différentes politiques d'allocation et avec différentes applications pour avoir différents patterns d'accès au \emph{PFS}. Ces évaluations, ont été effectuées sur le supercalculateur \emph{MareNostrum 4} (\emph{MN4}) en utilisant un outil appelé FORGE (I/O \textbf{For}wardin\textbf{g E}xplorer) qui permet de relancer les profils \emph{I/O} des applications.

Pour obtenir les résultats, ils ont fait des traces pour connaître les patterns d'accès des applications au \emph{PFS}. Ils ont collecté le volume total des données transféré et le nombre de processus qui font des requêtes \emph{I/O}. Avec ces traces, ils ont créé des petits benchmarks pour reproduire les patterns d'accès et faire des tests de performance.

Ils n'ont pas eu besoin de faire de profiling, car ils ne s'intéressent qu'aux politiques d'allocation.

Ils ont exécuté 189 patterns sur la machine \emph{MN4} et ils ont fait des groupes de 16 patterns pour simuler chaque politique (Un pattern représente une application).
Ils ont donc généré 10 000 groupes de 16 patterns qui prennent le même temps d'exécution.
Ils ont utilisé jusqu'à 128 \noeudsIOforwarding{}, 8 par application ($128/16=8$). Avec un nombre de \noeudsDeCalculs{} entre 88 et 512 et une médiane de 256.

La bande passante de chaque groupe est calculée par la somme des nombre d'écriture plus le nombre de lecture le tout divisé par le temps d'exécution. ($(nbEcriture + nbLecture) / tempsDExecution$).
% W = Write, R = Read, runtime = runningTime
\begin{equation*}aggregate\ BW=\sum_{a=1}^{16}\left(\frac{W_{a}+R_{a}}{runtime_{a}}\right)\end{equation*}

Cette évaluation montre qu'il est possible d'améliorer l'utilisation de la bande passante.
Ils ont aussi vu que toutes les applications n'ont pas les mêmes performances avec le même nombre de \noeudsIO{}. Cette différence existe, car chaque application a un pattern d'accès au \emph{PFS} différent. Ils ont remarqué que certaines applications avaient des patterns similaires.

\section{Propositions de l'article}

La problématique d'une politique d'allocation peut être représentée comme suit :
Pour un ensemble de tâches ou job à exécuter et un nombre fixe de \noeudsIO{}, il faut déterminer le nombre de \noeudsIOforwarding{} qui permet de maximiser l'utilisation de la bande passante globale.
Cette problématique peut être considérée comme un problème d'optimisation.

Pour répondre à cette problématique et permettre l'allocation dynamique l'article propose une nouvelle politique d'allocation ainsi qu'un service permettant l'allocation dynamique.

\subsection{La politique d'allocations basée sur \emph{MCKP}}

La politique d'allocation basée sur \textbf{MCKP} (\emph{Multiple-Choice Knapsack Problem}) cherche la meilleure répartition possible des \noeudsIOforwarding{} aux \noeudsDeCalculs{}.
Pour cela, cette politique cherche à maximiser la bande passante globale en donnant plus de \noeudsIOforwarding{} aux applications qui en ont le plus besoin et moins aux autres. Ce problème d'optimisation est dérivé du problème \emph{0-1 Knapsack}.
Pour effectuer la maximisation de la bande passante, l'algorithme vérifie que chaque tâche a bien une taille et que le nombre global de \noeudsIOforwarding{} calculé ne dépasse pas le nombre de \noeudsIO{} disponibles.

Ce problème fait partie de la classe de complexité en temps \emph{NP-hard} mais une solution peut être obtenue par "Dynamic Programming" qui est en temps \emph{pseudo-polynomial}.

Le nombre de \noeudsDeCalculs{} doit être divisible par le nombre de \noeudsIOforwarding{} pour améliorer l'équilibrage de la charge.

% MCKP :
% - Ce problème cherche à maximiser la bande passante globale en donnant plus de noeuds I/O aux applications qui en ont le plus besoin.
% - un problème d'optimisation
% - derived from the 0-1 Knapsack
% - items divide in $k$ classes of $N_i$ items
% ($N$ = ensemble des nombres d'items par classes)
% $Items = {a; b; c; d; e; f; g}, k <- 2, Items/k = C <- {{a; b; c}; {d; e; f; g}},$
% $card(C_1) = 3 = N_1, card(C_2) = 3 = N_2$
% - $x_{ij} = 1$ ssi item $j$ is chosen in class $N_i$
% - $w_i$ is the weight for the iéme items that represent number of I/O nodes.
% - $W$ the total number of I/O nodes.
% - $p_i$ is the bandwidth.
% - problem is NP-hard
% - la solution est obtenue par "Dynamic Programming" qui a une complexité en temps pseudo-polynomial ($O(W\sum^{k}_{i=1}N_i)$)

\subsection{Le service permettant l'allocation dynamique (\emph{GekkoFWD})}

L'article propose un service \emph{I/O forwarding} appelé \emph{GekkoFWD} qui implémente la politique \textbf{MCKP}. Ce service permet à la demande (dynamiquement) et sans perturber l'application le changement de politiques d'allocation et le changement du \noeudsIOforwarding{}. Il fonctionne au niveau utilisateur, il ne nécessite pas de modification du code des applications et il est simple à déployer. Cette simplicité en fait une solution utile.
Ce service est basé sur \emph{GekkoFS} qui est un système de fichier local à un noeud et qui peut se connecter à la plupart des \emph{PFS} existants.

\subsubsection{\emph{GekkoFS}}

\emph{GekkoFS} est un système de fichiers local qui est exécuté sur les \noeudsDeCalculs{}. Ce système est utilisé comme un \emph{burst-buffer}. Comme son nom l'indique, c'est une mémoire tampon qui se met entre l'application et le \emph{PFS} dans le but d'améliorer la performance des accès \emph{I/O}. Cette amélioration est en partie due à la diminution de la charge sur le \emph{PFS} quand il y a un pic de demande.

Ce système permet aussi l'exécution des requêtes \emph{I/O} en parallèle de l'exécution du calcul, ce qui permet d'augmenter l'utilisation de la bande passante.

Il fournit aussi un système de nom qui est partagé entre tous les \noeudsDeCalculs{}. Ce mécanisme peut être remplacé par un \emph{PFS}.

\subsubsection{Application de techniques d'optimisation (\emph{AGIOS})}

\emph{GekkoFWD} permet d'appliquer des techniques d'optimisation de façon transparente. Pour ce faire, ils ont ajouté la bibliothèque \emph{AGIOS} dans \emph{GekkoFWD}. Cette bibliothèque fournit plusieurs algorithmes d'ordonnancement.
\emph{GekkoFWD} peut donc utiliser différents ordonnanceurs sur les requêtes. Ceci permet la planification des requêtes au niveau des données.

\section{Algorithme}

Grâce à \emph{GekkoFWD}, \emph{GekkoFS} est utilisé comme un noeud intermédiaire entre les \noeudsDeCalculs{} et les \noeudsIO{}. Pour cela, \emph{GekkoFS} capture les requêtes que fait l'application au \emph{PFS}. Cette capture est transparente et se fait en interceptant les appels systèmes. Une fois les requêtes capturées, \emph{GekkoFWD} transfère les requêtes à un seul serveur qui va les passer à \emph{AGIOS} pour ordonnancer le moment où elles seront traitées. Grâce aux requêtes, il est possible de déterminer quelle politique d'allocation appliquée.

Pour savoir quand le mappage à changer, on ajoute un thread grâce à \emph{GekkoFS}.

Le changement de politique se fait au démarrage ou au changement de la liste des applications lancées.

\section{Les performances}

Ils ont fait les expérimentations sur la plateforme \emph{Grid 5000} (\emph{G5K}) avec 2 clusters à Nancy : \emph{Grimoire} (8 noeuds) et \emph{Gros} (124 noeuds).

Ils ont utilisé 5 noyaux d'applications différentes ainsi que les micro-benchmarks \emph{IOR} :
\begin{enumerate}
  \item \emph{S3D I/O Kernel} : S3D
  \item \emph{MADBench2} : MAD
  \item \emph{HACC-IO} : HACC
  \item \emph{S3aSim} : SIM
  \item \emph{NAS BT-IO} : BT-C, BT-D
  \item [IOR] \emph{MPI-IO / POSIX} : IOR-MPI, POSIX-S, POSIX-L
\end{enumerate}

Ils ont mesuré la bande passante pour chaque application et il confirme les résultats de \emph{FORGE}. Ils ont fait ce test avec des nombres de noeuds et des nombres de processus différents.
Les ensembles de tâches pour tester le changement d'allocation dynamique étaient composés de BT-C, BT-D, IOR-MPI, POSIX-L, MAD, et S3D.

Il constate bien que les accès statiques ne sont pas très efficaces sauf pour S3D. Même constatation pour l'allocation par taille. Dans ces 2 cas, on voit que par exemple \emph{IOR-MPI} pourrait être bien meilleurs avec plus de \noeudsIOforwarding{}. Il constate bien une nette amélioration avec leur implémentation \emph{MCKP}. Le gain global d'utilisation de la bande passante est jusqu'à 85\% par rapport à la politique statique.

Ils ont comparé différents scénarios pour montrer que leur implémentation fonctionne bien.

\section{Les articles qu'il référence}

Les articles référencés parlent de :
\begin{itemize}
  \item Tests de performance des différentes politiques d'allocation.
  \item De l'optimisation.
  \item Des gestions d'\emph{I/O} des supercalculateurs.
  \item De \emph{I/O Forwarding} à la demande.
  \item Du service \emph{GekkoFS}.
  \item D'ordonnancement.
\end{itemize}

% load all bibliographies
\bibliography{biblio}
\nocite{*}

\end{document}
